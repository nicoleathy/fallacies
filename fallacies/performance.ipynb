{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0.2  Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       " 0             0           0             0               0                 0   \n",
       " 1             1           1             1               1                 1   \n",
       " 2             2           2             2               2                 2   \n",
       " 3             3           3             3               3                 3   \n",
       " 4             4           4             4               4                 4   \n",
       " \n",
       "    Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1  \\\n",
       " 0                   0                     0                       0   \n",
       " 1                   1                     1                       1   \n",
       " 2                   2                     2                       2   \n",
       " 3                   3                     3                       3   \n",
       " 4                   4                     4                       4   \n",
       " \n",
       "    Unnamed: 0.1.1.1.1.1.1.1  \\\n",
       " 0                      1436   \n",
       " 1                       557   \n",
       " 2                       772   \n",
       " 3                       625   \n",
       " 4                      1843   \n",
       " \n",
       "                                       source_article         updated_label  \\\n",
       " 0          company's slogan \"Expect More. Pay Less.\"     appeal to emotion   \n",
       " 1  The bigger a child's shoe size, the better the...       false causality   \n",
       " 2  Since many people believe this, then it must b...            ad populum   \n",
       " 3  Senator Randall isn't lying when she says she ...    circular reasoning   \n",
       " 4  A mother is telling her daughter that she went...  fallacy of relevance   \n",
       " \n",
       "                                      masked_articles  \n",
       " 0    company 's slogan \" Expect More . Pay Less . \"   \n",
       " 1  The bigger MSK<0> shoe size , the better MSK<0...  \n",
       " 2  Since many people believe this , then it must ...  \n",
       " 3  MSK<0> is n't MSK<1> when MSK<0> says MSK<0> M...  \n",
       " 4  MSK<0> is MSK<1> MSK<2> that MSK<0> went over ...  ,\n",
       "    Unnamed: 0.2  Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       " 0             0           0             0               0                 0   \n",
       " 1             1           1             1               1                 1   \n",
       " 2             2           2             2               2                 2   \n",
       " 3             3           3             3               3                 3   \n",
       " 4             4           4             4               4                 4   \n",
       " \n",
       "    Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1  \\\n",
       " 0                   0                     0                       0   \n",
       " 1                   1                     1                       1   \n",
       " 2                   2                     2                       2   \n",
       " 3                   3                     3                       3   \n",
       " 4                   4                     4                       4   \n",
       " \n",
       "    Unnamed: 0.1.1.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1.1.1  \\\n",
       " 0                         0                        1256   \n",
       " 1                         1                        1455   \n",
       " 2                         2                        2199   \n",
       " 3                         3                         744   \n",
       " 4                         4                        1181   \n",
       " \n",
       "                                       source_article          updated_label  \\\n",
       " 0  \"Just like students are given a couple of week...       fallacy of logic   \n",
       " 1  You don’t have to do this. My grandmother is i...      appeal to emotion   \n",
       " 2  I know five people from Kentucky. They are all...  faulty generalization   \n",
       " 3  Pvt. Joe Bowers: What are these electrolytes? ...     circular reasoning   \n",
       " 4  This is a fallacy of irrelevance that is based...             ad hominem   \n",
       " \n",
       "                                      masked_articles  \n",
       " 0  \" Just like students are given a couple of MSK...  \n",
       " 1  You do n’t have to do this . MSK<0> grandmothe...  \n",
       " 2  I know MSK<0> . MSK<0> are all MSK<1> . Theref...  \n",
       " 3  MSK<1> : What are MSK<2> ? Do you even know ? ...  \n",
       " 4  This is a fallacy of irrelevance that is based...  ,\n",
       "    Unnamed: 0.2  Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       " 0             0           0             0               0                 0   \n",
       " 1             1           1             1               1                 1   \n",
       " 2             2           2             2               2                 2   \n",
       " 3             3           3             3               3                 3   \n",
       " 4             4           4             4               4                 4   \n",
       " \n",
       "    Unnamed: 0.1.1.1.1  Unnamed: 0.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1  \\\n",
       " 0                   0                     0                       0   \n",
       " 1                   1                     1                       1   \n",
       " 2                   2                     2                       2   \n",
       " 3                   3                     3                       3   \n",
       " 4                   4                     4                       4   \n",
       " \n",
       "    Unnamed: 0.1.1.1.1.1.1.1  Unnamed: 0.1.1.1.1.1.1.1.1  \\\n",
       " 0                         0                        1738   \n",
       " 1                         1                         168   \n",
       " 2                         2                        1331   \n",
       " 3                         3                         449   \n",
       " 4                         4                         130   \n",
       " \n",
       "                                       source_article          updated_label  \\\n",
       " 0  People who drive big cars probably hate the en...   fallacy of extension   \n",
       " 1      White men can't jump. No, really, they can't!  faulty generalization   \n",
       " 2  'Cotton and grain crops were lower this year t...       fallacy of logic   \n",
       " 3  \"Why are you hitting your computer!?\"\\n\"The la...        false causality   \n",
       " 4      All students are good and all clowns are bad.  faulty generalization   \n",
       " \n",
       "                                      masked_articles  \n",
       " 0  People who drive big cars probably hate the en...  \n",
       " 1  MSK<0> ca n't jump . No , really , MSK<0> ca n...  \n",
       " 2  ' Cotton and grain crops were lower this year ...  \n",
       " 3  \" Why are MSK<0> MSK<1> MSK<0> !? \" \" The last...  \n",
       " 4    All students are good and all clowns are bad .   ,\n",
       "            Original Name    Understandable Name  \\\n",
       " 0  faulty generalization  faulty generalization   \n",
       " 1        false causality        false causality   \n",
       " 2     circular reasoning     circular reasoning   \n",
       " 3             ad populum   appeal to popularity   \n",
       " 4             ad hominem        personal attack   \n",
       " \n",
       "                                          Description  \\\n",
       " 0  an informal fallacy wherein a conclusion is dr...   \n",
       " 1  statement that jumps to a conclusion implying ...   \n",
       " 2  when the end of an argument comes back to the ...   \n",
       " 3  a fallacious argument which is based on affirm...   \n",
       " 4   instead of addressing someone's argument or p...   \n",
       " \n",
       "                                         Logical Form  \\\n",
       " 0  Sample S is taken from population P. Sample S ...   \n",
       " 1  A occurred, then B occurred.\\nTherefore, A cau...   \n",
       " 2  X is true because of Y.\\n\\nY is true because o...   \n",
       " 3  A lot of people believe X.Therefore, X must be...   \n",
       " 4  Person 1 is claiming Y.\\n\\nPerson 1 is a moron...   \n",
       " \n",
       "                             Source for Logical Form   \\\n",
       " 0  https://www.logicallyfallacious.com/logicalfal...   \n",
       " 1  https://en.wikipedia.org/wiki/Post_hoc_ergo_pr...   \n",
       " 2  https://www.logicallyfallacious.com/logicalfal...   \n",
       " 3  https://www.logicallyfallacious.com/logicalfal...   \n",
       " 4  https://www.logicallyfallacious.com/logicalfal...   \n",
       " \n",
       "                                  Masked Logical Form  \n",
       " 0  <MSK1> is taken from <MSK2>. <MSK1> is a very ...  \n",
       " 1  <MSK1> occurred, then <MSK2> occurred.\\nTheref...  \n",
       " 2  <MSK1> is true because of <MSK2>.\\n\\n<MSK2> is...  \n",
       " 3  A lot of people believe <MSK1>.Therefore, <MSK...  \n",
       " 4  <MSK1> is claiming <MSK2>.\\n\\n<MSK1> is a moro...  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "edu_train = pd.read_csv(\"edu_train.csv\")\n",
    "edu_dev = pd.read_csv(\"edu_dev.csv\")\n",
    "edu_test = pd.read_csv(\"edu_test.csv\")\n",
    "mappings = pd.read_csv(\"mappings.csv\")\n",
    "\n",
    "# Display the first few rows of each dataset to understand their structure\n",
    "edu_train.head(), edu_dev.head(), edu_test.head(), mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_533497/1524631202.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edu_train_cleaned['updated_label'] = edu_train_cleaned['updated_label'].map(label2id)\n",
      "/tmp/ipykernel_533497/1524631202.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edu_dev_cleaned['updated_label'] = edu_dev_cleaned['updated_label'].map(label2id)\n",
      "/tmp/ipykernel_533497/1524631202.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  edu_test_cleaned['updated_label'] = edu_test_cleaned['updated_label'].map(label2id)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                      source_article  updated_label\n",
       " 0          company's slogan \"Expect More. Pay Less.\"            6.0\n",
       " 1  The bigger a child's shoe size, the better the...            1.0\n",
       " 2  Since many people believe this, then it must b...            NaN\n",
       " 3  Senator Randall isn't lying when she says she ...            2.0\n",
       " 4  A mother is telling her daughter that she went...            NaN,\n",
       "                                       source_article  updated_label\n",
       " 0  \"Just like students are given a couple of week...            NaN\n",
       " 1  You don’t have to do this. My grandmother is i...            6.0\n",
       " 2  I know five people from Kentucky. They are all...            0.0\n",
       " 3  Pvt. Joe Bowers: What are these electrolytes? ...            2.0\n",
       " 4  This is a fallacy of irrelevance that is based...            NaN,\n",
       "                                       source_article  updated_label\n",
       " 0  People who drive big cars probably hate the en...            NaN\n",
       " 1      White men can't jump. No, really, they can't!            0.0\n",
       " 2  'Cotton and grain crops were lower this year t...            NaN\n",
       " 3  \"Why are you hitting your computer!?\"\\n\"The la...            1.0\n",
       " 4      All students are good and all clowns are bad.            0.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns from the datasets\n",
    "edu_train_cleaned = edu_train[['source_article', 'updated_label']]\n",
    "edu_dev_cleaned = edu_dev[['source_article', 'updated_label']]\n",
    "edu_test_cleaned = edu_test[['source_article', 'updated_label']]\n",
    "\n",
    "# Create a mapping from the 'Understandable Name' in mappings to an integer id\n",
    "label2id = {row['Understandable Name']: idx for idx, row in mappings.iterrows()}\n",
    "id2label = {idx: row['Understandable Name'] for idx, row in mappings.iterrows()}\n",
    "\n",
    "# Map the labels in the datasets to integer ids\n",
    "edu_train_cleaned['updated_label'] = edu_train_cleaned['updated_label'].map(label2id)\n",
    "edu_dev_cleaned['updated_label'] = edu_dev_cleaned['updated_label'].map(label2id)\n",
    "edu_test_cleaned['updated_label'] = edu_test_cleaned['updated_label'].map(label2id)\n",
    "\n",
    "# Verify the preprocessing\n",
    "edu_train_cleaned.head(), edu_dev_cleaned.head(), edu_test_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                      source_article  updated_label\n",
       " 0          company's slogan \"Expect More. Pay Less.\"              6\n",
       " 1  The bigger a child's shoe size, the better the...              1\n",
       " 3  Senator Randall isn't lying when she says she ...              2\n",
       " 5  A mother tells her children not to leave the y...              6\n",
       " 6  If we ban Hummers because they are bad for the...              0,\n",
       "                                        source_article  updated_label\n",
       " 1   You don’t have to do this. My grandmother is i...              6\n",
       " 2   I know five people from Kentucky. They are all...              0\n",
       " 3   Pvt. Joe Bowers: What are these electrolytes? ...              2\n",
       " 7   If we use one more can of hairspray this month...              0\n",
       " 11   The best example of this fallacy is presented...              1,\n",
       "                                       source_article  updated_label\n",
       " 1      White men can't jump. No, really, they can't!              0\n",
       " 3  \"Why are you hitting your computer!?\"\\n\"The la...              1\n",
       " 4      All students are good and all clowns are bad.              0\n",
       " 7  Paige wants to play a guitar solo on our next ...              0\n",
       " 9                     something that kills is deadly              2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with missing labels from all datasets\n",
    "edu_train_cleaned = edu_train_cleaned.dropna(subset=['updated_label'])\n",
    "edu_dev_cleaned = edu_dev_cleaned.dropna(subset=['updated_label'])\n",
    "edu_test_cleaned = edu_test_cleaned.dropna(subset=['updated_label'])\n",
    "\n",
    "# Convert labels to integers (they may have been cast as floats due to NaN handling)\n",
    "edu_train_cleaned['updated_label'] = edu_train_cleaned['updated_label'].astype(int)\n",
    "edu_dev_cleaned['updated_label'] = edu_dev_cleaned['updated_label'].astype(int)\n",
    "edu_test_cleaned['updated_label'] = edu_test_cleaned['updated_label'].astype(int)\n",
    "\n",
    "# Verify the cleaned datasets\n",
    "edu_train_cleaned.head(), edu_dev_cleaned.head(), edu_test_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama-2-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1baec094c5164b1e9bfc48e7cbca316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-hf and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ae706463bd431aa76a4a5bb99422ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/757 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3659594a524ff6b6ce5af549da794a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e1eedbe9bd43cd89ebd81debee379e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/121 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zxwang/miniconda3/envs/comp6/lib/python3.11/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/zxwang/miniconda3/envs/comp6/lib/python3.11/site-packages/accelerate/accelerator.py:482: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "r.nvmlDeviceGetNvLinkRemoteDeviceType_ INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1720538437738/work/c10/cuda/driver_api.cpp\":27, please report a bug to PyTorch. Can't find nvmlDeviceGetNvLinkRemoteDeviceType: /lib/x86_64-linux-gnu/libnvidia-ml.so.1: undefined symbol: nvmlDeviceGetNvLinkRemoteDeviceType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 84\u001b[0m\n\u001b[1;32m     68\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     69\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     70\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     dataloader_pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Trainer to handle training\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     94\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/transformers/trainer.py:529\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    528\u001b[0m ):\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/transformers/trainer.py:776\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 776\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/transformers/modeling_utils.py:2796\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2792\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2793\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2794\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2795\u001b[0m         )\n\u001b[0;32m-> 2796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/comp6/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: r.nvmlDeviceGetNvLinkRemoteDeviceType_ INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1720538437738/work/c10/cuda/driver_api.cpp\":27, please report a bug to PyTorch. Can't find nvmlDeviceGetNvLinkRemoteDeviceType: /lib/x86_64-linux-gnu/libnvidia-ml.so.1: undefined symbol: nvmlDeviceGetNvLinkRemoteDeviceType"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Load your datasets\n",
    "edu_train = pd.read_csv(\"edu_train.csv\")\n",
    "edu_dev = pd.read_csv(\"edu_dev.csv\")\n",
    "edu_test = pd.read_csv(\"edu_test.csv\")\n",
    "mappings = pd.read_csv(\"mappings.csv\")\n",
    "\n",
    "# Clean the datasets by removing unwanted columns and mapping labels\n",
    "edu_train_cleaned = edu_train[['source_article', 'updated_label']].dropna()\n",
    "edu_dev_cleaned = edu_dev[['source_article', 'updated_label']].dropna()\n",
    "edu_test_cleaned = edu_test[['source_article', 'updated_label']].dropna()\n",
    "\n",
    "# Create a mapping from 'Understandable Name' to integer ids\n",
    "label2id = {row['Understandable Name']: idx for idx, row in mappings.iterrows()}\n",
    "id2label = {idx: row['Understandable Name'] for idx, row in mappings.iterrows()}\n",
    "\n",
    "# Map the labels to integer ids and remove NaN values\n",
    "edu_train_cleaned['updated_label'] = edu_train_cleaned['updated_label'].map(label2id)\n",
    "edu_train_cleaned = edu_train_cleaned.dropna(subset=['updated_label'])\n",
    "edu_train_cleaned['updated_label'] = edu_train_cleaned['updated_label'].astype(int)\n",
    "\n",
    "edu_dev_cleaned['updated_label'] = edu_dev_cleaned['updated_label'].map(label2id)\n",
    "edu_dev_cleaned = edu_dev_cleaned.dropna(subset=['updated_label'])\n",
    "edu_dev_cleaned['updated_label'] = edu_dev_cleaned['updated_label'].astype(int)\n",
    "\n",
    "edu_test_cleaned['updated_label'] = edu_test_cleaned['updated_label'].map(label2id)\n",
    "edu_test_cleaned = edu_test_cleaned.dropna(subset=['updated_label'])\n",
    "edu_test_cleaned['updated_label'] = edu_test_cleaned['updated_label'].astype(int)\n",
    "\n",
    "# Load the LLaMA-2-7B model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add padding token if not present\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add new pad token\n",
    "\n",
    "# Update pad token ID in model configuration\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(mappings))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # Ensure model is aware of the pad token\n",
    "\n",
    "# Resize token embeddings of the model to account for the new pad_token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Tokenize the datasets and ensure the labels are integers\n",
    "def tokenize_function_with_labels(examples):\n",
    "    tokens = tokenizer(examples[\"source_article\"], padding=\"max_length\", truncation=True)\n",
    "    tokens[\"labels\"] = [int(label) for label in examples[\"updated_label\"]]\n",
    "    return tokens\n",
    "\n",
    "train_dataset = Dataset.from_pandas(edu_train_cleaned).map(tokenize_function_with_labels, batched=True)\n",
    "dev_dataset = Dataset.from_pandas(edu_dev_cleaned).map(tokenize_function_with_labels, batched=True)\n",
    "test_dataset = Dataset.from_pandas(edu_test_cleaned).map(tokenize_function_with_labels, batched=True)\n",
    "\n",
    "# Define metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,  # Adjust batch size based on GPU memory\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    # Enable distributed data parallel if multiple GPUs are available\n",
    "    dataloader_pin_memory=True,\n",
    ")\n",
    "\n",
    "# Trainer to handle training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
